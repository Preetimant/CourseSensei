{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright Â© 2025 Preetimant Bora Bhowal. All rights reserved.\n",
        "# Unauthorized copying, distribution, or use of this file is strictly prohibited."
      ],
      "metadata": {
        "id": "n8OnzXN0_04g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1x-cT6AtRKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380a6ea5-580b-4dcc-aac3-1e8c35a13551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx pdfplumber owlready2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N9D2skTdtep6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd04d23-d34b-45bb-96f3-79f248654f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: owlready2 in /usr/local/lib/python3.11/dist-packages (0.47)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from docx import Document\n",
        "import re\n",
        "import pdfplumber\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import uuid\n",
        "import zipfile\n",
        "import time\n",
        "from datetime import datetime\n",
        "import owlready2\n",
        "from owlready2 import *\n",
        "from owlready2 import World, get_ontology, DataProperty, ObjectProperty, FunctionalProperty\n",
        "import logging"
      ],
      "metadata": {
        "id": "dZVn7HYLtkG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Directory Crawler**"
      ],
      "metadata": {
        "id": "sVywmegvtnlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_course_outlines(root_dir):\n",
        "    course_files = []\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        # Skip \"Output\" folder\n",
        "        if \"Output\" in root.split(os.sep):\n",
        "            continue\n",
        "        for file in files:\n",
        "            if file.lower().endswith((\".pdf\", \".docx\")):\n",
        "                # Extract program and term from path\n",
        "                path_parts = root.split(os.sep)\n",
        "                program = path_parts[-2] if \"term_\" in path_parts[-1] else None\n",
        "                term = path_parts[-1] if \"term_\" in path_parts[-1] else None\n",
        "\n",
        "                if program and term:\n",
        "                    course_files.append({\n",
        "                        \"path\": os.path.join(root, file),\n",
        "                        \"program\": program,\n",
        "                        \"term\": term,\n",
        "                        \"filename\": file\n",
        "                    })\n",
        "    return course_files"
      ],
      "metadata": {
        "id": "HIUKaa0OtmgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Common Code and Pattern**"
      ],
      "metadata": {
        "id": "Ex4DAGRatt2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default(value, default=\"NA\"):\n",
        "    \"\"\"\n",
        "    Returns the default value if the provided value is None,\n",
        "    empty, or just a hyphen.\n",
        "    \"\"\"\n",
        "    if value is None or value.strip() == \"\" or value.strip() == \"-\":\n",
        "        return default\n",
        "    return value.strip()"
      ],
      "metadata": {
        "id": "_xjB1F9ftxXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "course_metadata_keys = {\n",
        "    \"Course Code and Course Title\": r\"(?i).*\\b(course code|course title)\\b.*\",\n",
        "    \"Course type\": r\"(?i).*\\bcourse type\\b.*\",\n",
        "    \"Pre-requisites (if any)\": r\"(?i).*\\b(pre[-\\s]?requisites)( \\(if any\\))?\\b.*\",\n",
        "    \"Course Credit\": r\"(?i).*\\b(course credit|course unit[s]?)\\b.*\",\n",
        "    \"Total no. of sessions\": r\"(?i).*\\btotal no\\.? of sessions\\b.*\",\n",
        "    \"Session Duration\": r\"(?i).*\\bsession duration\\b.*\",\n",
        "    \"Term\": r\"(?i).*\\b(term|semester)\\b.*\",\n",
        "    \"Year and Batch\": r\"(?i).*\\byear and batch\\b.*\",\n",
        "    \"Sections (if any)\": r\"(?i).*\\bsections\\b.*\"\n",
        "}\n",
        "\n",
        "instructor_keys = {\n",
        "    \"Instructor(s)\": r\"(?i).*\\binstructor\\b.*\",\n",
        "    \"Contact Details\": r\"(?i).*\\bcontact\\s*details\\b.*\",\n",
        "    \"Office\": r\"(?i).*\\boffice\\b.*\",\n",
        "    \"Consultation Hours\": r\"(?i).*\\bconsultation\\s*hours\\b.*\"\n",
        "}\n",
        "\n",
        "assessment_col_patterns = {\n",
        "    \"Assessment Tool\": r\"(?i).*\\bAssessment\\b.*\",\n",
        "    \"Percentage\": r\"(?i).*\\bPercentage\\b.*\",\n",
        "    \"Description\": r\"(?i).*\\bDescription\\b.*\"\n",
        "}\n",
        "\n",
        "session_plan_col_patterns = {\n",
        "    \"Session\": r\"(?i).*\\bSession\\b.*\",\n",
        "    \"Module\": r\"(?i).*\\bModule\\b.*\",\n",
        "    \"Topic\": r\"(?i).*\\b(Topic|Readings)\\b.*\",\n",
        "    \"Chapter No / Reading material / Cases\": r\"(?i).*\\b(Chapter No|Reading[s]?|Case)\\b.*\"\n",
        "}\n",
        "\n",
        "# A valid session pattern: one or more digits, optionally with a range.\n",
        "valid_session_pattern = re.compile(r'^\\d+([\\s,-]\\d+)?$')"
      ],
      "metadata": {
        "id": "7RElQxvKt5gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intro_pattern = re.compile(\n",
        "        r\"(?m)^\\s*Introduction\\s*(?P<intro_text>.*?)(?=Learning Outcomes|Textbook|Pedagogy|Evaluation|Assessment)\",\n",
        "        re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "lo_pattern = re.compile(\n",
        "    r\"(?m)^\\s*Learning Outcomes\\s*(?:/Course Objectives)?\\s*(?P<lo_text>.*?)(?=Textbook|Reference|Pedagogy|Evaluation|Assessment)\",\n",
        "    re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "ped_pattern = re.compile(\n",
        "    r\"(?m)^\\s*Pedagogy Used\\s*(?:/Learning Process)?\\s*(?P<ped_text>.*?)(?=Evaluation|Assessment)\",\n",
        "    re.DOTALL | re.IGNORECASE)"
      ],
      "metadata": {
        "id": "BLS5kyaOU8la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DOCX Processor**"
      ],
      "metadata": {
        "id": "PF6yUnkIt6nP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Text Sections"
      ],
      "metadata": {
        "id": "u3uYr32tUO2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_sections_from_docx(file_path):\n",
        "    \"\"\"\n",
        "    Extracts basic text sections (\"Introduction\", \"Learning Outcomes\", \"Pedagogy\")\n",
        "    from a DOCX file.\n",
        "    \"\"\"\n",
        "    document = Document(file_path)\n",
        "    full_text = \"\\n\".join([para.text for para in document.paragraphs])\n",
        "\n",
        "    intro_match = intro_pattern.search(full_text)\n",
        "    lo_match = lo_pattern.search(full_text)\n",
        "    ped_match = ped_pattern.search(full_text)\n",
        "\n",
        "    return {\n",
        "        \"Introduction\": intro_match.group(\"intro_text\").strip() if intro_match else \"NA\",\n",
        "        \"Learning Outcomes\": lo_match.group(\"lo_text\").strip() if lo_match else \"NA\",\n",
        "        \"Pedagogy\": ped_match.group(\"ped_text\").strip() if ped_match else \"NA\"\n",
        "    }"
      ],
      "metadata": {
        "id": "LqgQ0D7Kt8s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Tables"
      ],
      "metadata": {
        "id": "1NSRgmBnUQtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_merged_cell(cell):\n",
        "    \"\"\"\n",
        "    Checks if a cell is a merged cell (i.e. a continuation cell)\n",
        "    by looking at its underlying XML for a <w:vMerge> element.\n",
        "    \"\"\"\n",
        "    xml = cell._tc.xml\n",
        "    if \"<w:vMerge\" in xml:\n",
        "        # If the cell indicates a restart, then it's the first cell (not a continuation)\n",
        "        if 'w:val=\"restart\"' in xml:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "Aa4-FvTVuC3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cell_value(cell, prev_value=None):\n",
        "    \"\"\"\n",
        "    Returns the cell's value. If the cell is blank and is a merged cell,\n",
        "    it returns the previous row's value (if provided); otherwise \"NA\".\n",
        "    Otherwise, returns the cleaned text.\n",
        "    \"\"\"\n",
        "    text = cell.text.strip()\n",
        "    if text == \"\":\n",
        "        if is_merged_cell(cell):\n",
        "            return prev_value if prev_value is not None else \"NA\"\n",
        "        else:\n",
        "            return \"NA\"\n",
        "    else:\n",
        "        return get_default(cell.text)"
      ],
      "metadata": {
        "id": "i0Agls1iuFGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tables_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "\n",
        "    # Initialize dictionaries with default values \"NA\"\n",
        "    course_metadata = {key: \"NA\" for key in course_metadata_keys}\n",
        "    instructor_details = {key: \"NA\" for key in instructor_keys}\n",
        "    assessment = []\n",
        "    session_plan = []\n",
        "    session_count_expected = None\n",
        "    session_rows_extracted = 0\n",
        "\n",
        "    # Iterate over each table in the document\n",
        "    for table in doc.tables:\n",
        "        if len(table.rows) == 0 or len(table.rows[0].cells) < 2:\n",
        "            continue\n",
        "\n",
        "        # Get header row texts (lower-case for metadata/instructor detection)\n",
        "        header_lower = [cell.text.strip().lower() for cell in table.rows[0].cells]\n",
        "        course_patterns = list(course_metadata_keys.values())\n",
        "        instructor_patterns = list(instructor_keys.values())\n",
        "\n",
        "        # If the header row indicates this is a metadata/instructor table\n",
        "        if any(any(re.search(pattern, text, re.IGNORECASE) for pattern in course_patterns + instructor_patterns)\n",
        "               for text in header_lower):\n",
        "            prev_row_values = {}  # Reset for this table\n",
        "            for row in table.rows:\n",
        "                if len(row.cells) < 2:\n",
        "                    continue\n",
        "                # Process cells with merged-cell logic using get_cell_value\n",
        "                cells = []\n",
        "                for idx, cell in enumerate(row.cells):\n",
        "                    cell_value = get_cell_value(cell, prev_row_values.get(idx))\n",
        "                    cells.append(cell_value)\n",
        "                # Update previous row values for non-\"NA\" cells\n",
        "                prev_row_values = {i: cells[i] for i in range(len(cells)) if cells[i] != \"NA\"}\n",
        "\n",
        "                # Use first two columns as key and value\n",
        "                key_text = cells[0]\n",
        "                value = cells[1] if len(cells) > 1 else \"NA\"\n",
        "\n",
        "                # Check against course metadata keys (using regex, case-insensitive)\n",
        "                for canonical, pattern in course_metadata_keys.items():\n",
        "                    if re.search(pattern, key_text, re.IGNORECASE):\n",
        "                        course_metadata[canonical] = value\n",
        "                        if canonical == \"Total no. of sessions\":\n",
        "                            try:\n",
        "                                session_count_expected = int(value)\n",
        "                            except ValueError:\n",
        "                                session_count_expected = None\n",
        "                        break\n",
        "\n",
        "                # Check against instructor keys\n",
        "                for canonical, pattern in instructor_keys.items():\n",
        "                    if re.search(pattern, key_text, re.IGNORECASE):\n",
        "                        instructor_details[canonical] = value\n",
        "                        break\n",
        "            continue  # Move to next table\n",
        "\n",
        "        # Process Assessment table (Row-Based) using header mapping and merged cells logic\n",
        "        assessment_header_mapping = {}\n",
        "        prev_row_values = {}  # Reset for this table\n",
        "        for i, cell in enumerate(table.rows[0].cells):\n",
        "            header_text = cell.text.strip()\n",
        "            for canonical, pattern in assessment_col_patterns.items():\n",
        "                if re.search(pattern, header_text):\n",
        "                    assessment_header_mapping[canonical] = i\n",
        "                    break\n",
        "        if len(assessment_header_mapping) > 0:\n",
        "            for row in table.rows[1:]:\n",
        "                cells = []\n",
        "                for idx, cell in enumerate(row.cells):\n",
        "                    cell_value = get_cell_value(cell, prev_row_values.get(idx))\n",
        "                    cells.append(cell_value)\n",
        "                for col_index in range(len(cells)):\n",
        "                    if cells[col_index] is None and col_index in prev_row_values:\n",
        "                        cells[col_index] = prev_row_values[col_index]\n",
        "                prev_row_values = {i: cells[i] for i in range(len(cells)) if cells[i] != \"NA\"}\n",
        "                # Ensure any still-missing cell is defaulted to \"NA\"\n",
        "                cells = [cell if cell is not None else \"NA\" for cell in cells]\n",
        "                row_data = {}\n",
        "                for canonical in assessment_col_patterns.keys():\n",
        "                    if canonical in assessment_header_mapping:\n",
        "                        idx = assessment_header_mapping[canonical]\n",
        "                        row_data[canonical] = cells[idx] if idx < len(cells) else \"NA\"\n",
        "                    else:\n",
        "                        row_data[canonical] = \"NA\"\n",
        "                assessment.append(row_data)\n",
        "            continue\n",
        "\n",
        "        # Process Session Plan table (Row-Based) using header mapping and merged cells logic\n",
        "        session_plan_header_mapping = {}\n",
        "        prev_row_values = {}  # Reset for this table\n",
        "        for i, cell in enumerate(table.rows[0].cells):\n",
        "            header_text = cell.text.strip()\n",
        "            for canonical, pattern in session_plan_col_patterns.items():\n",
        "                if re.search(pattern, header_text):\n",
        "                    session_plan_header_mapping[canonical] = i\n",
        "                    break\n",
        "        if len(session_plan_header_mapping) > 0:\n",
        "            for row in table.rows[1:]:\n",
        "                cells = []\n",
        "                for idx, cell in enumerate(row.cells):\n",
        "                    cell_value = get_cell_value(cell, prev_row_values.get(idx))\n",
        "                    cells.append(cell_value)\n",
        "                for col_index in range(len(cells)):\n",
        "                    if cells[col_index] is None and col_index in prev_row_values:\n",
        "                        cells[col_index] = prev_row_values[col_index]\n",
        "                prev_row_values = {i: cells[i] for i in range(len(cells)) if cells[i] != \"NA\"}\n",
        "                # Ensure any still-missing cell is defaulted to \"NA\"\n",
        "                cells = [cell if cell is not None else \"NA\" for cell in cells]\n",
        "                row_data = {}\n",
        "                for canonical in session_plan_col_patterns.keys():\n",
        "                    if canonical in session_plan_header_mapping:\n",
        "                        idx = session_plan_header_mapping[canonical]\n",
        "                        row_data[canonical] = cells[idx] if idx < len(cells) else \"NA\"\n",
        "                    else:\n",
        "                        row_data[canonical] = \"NA\"\n",
        "                # For the \"Session\" column, if the value is \"NA\" or blank, inherit from the previous row\n",
        "                if \"Session\" in row_data and (row_data[\"Session\"] == \"NA\" or row_data[\"Session\"].strip() == \"\"):\n",
        "                    if session_plan:\n",
        "                        row_data[\"Session\"] = session_plan[-1].get(\"Session\", \"NA\")\n",
        "                session_plan.append(row_data)\n",
        "                session_rows_extracted += 1\n",
        "                if session_count_expected and session_rows_extracted >= session_count_expected:\n",
        "                    break\n",
        "            continue\n",
        "\n",
        "    extracted_data = {\n",
        "        \"course_metadata\": course_metadata,\n",
        "        \"instructor_details\": instructor_details,\n",
        "        \"assessment\": assessment,\n",
        "        \"session_plan\": session_plan\n",
        "    }\n",
        "\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "I1CWKR3QuHxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PDF Processor**"
      ],
      "metadata": {
        "id": "M59WqlEsuMXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Text Sections"
      ],
      "metadata": {
        "id": "QNRCy9RcUHBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_sections_from_pdf(file_path):\n",
        "    \"\"\"\n",
        "    Extracts basic text sections (\"Introduction\", \"Learning Outcomes\", \"Pedagogy\")\n",
        "    from a PDF file.\n",
        "    \"\"\"\n",
        "    full_text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                full_text += text + \"\\n\"\n",
        "\n",
        "    intro_match = intro_pattern.search(full_text)\n",
        "    lo_match = lo_pattern.search(full_text)\n",
        "    ped_match = ped_pattern.search(full_text)\n",
        "\n",
        "    return {\n",
        "        \"Introduction\": intro_match.group(\"intro_text\").strip() if intro_match else \"NA\",\n",
        "        \"Learning Outcomes\": lo_match.group(\"lo_text\").strip() if lo_match else \"NA\",\n",
        "        \"Pedagogy\": ped_match.group(\"ped_text\").strip() if ped_match else \"NA\"\n",
        "    }"
      ],
      "metadata": {
        "id": "1KHH4NmeuOev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Tables"
      ],
      "metadata": {
        "id": "hXcayxVbUJ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tables_from_pdf(file_path):\n",
        "    extracted_data = {\n",
        "        \"course_metadata\": {},\n",
        "        \"instructor_details\": {},\n",
        "        \"assessment\": [],\n",
        "        \"session_plan\": []\n",
        "    }\n",
        "    session_count_expected = None\n",
        "    session_rows_extracted = 0\n",
        "    Session = \"\"\n",
        "\n",
        "    # current_table_type will remember if we are in an assessment or Session table.\n",
        "    # It can be set to \"assessment\", \"Session\", or None.\n",
        "    current_table_type = None\n",
        "\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            tables = page.extract_tables()\n",
        "            for table in tables:\n",
        "                if not table or not table[0]:\n",
        "                    continue\n",
        "                header_row = table[0]\n",
        "\n",
        "                # Determine table type using header matching.\n",
        "                is_metadata = any(re.search(course_metadata_keys[\"Course Code and Course Title\"], cell, re.IGNORECASE)\n",
        "                                  for cell in header_row if cell)\n",
        "                is_instructor = any(re.search(instructor_keys[\"Instructor(s)\"], cell, re.IGNORECASE)\n",
        "                                    for cell in header_row if cell)\n",
        "                is_assessment = any(re.search(assessment_col_patterns[\"Assessment Tool\"], cell, re.IGNORECASE)\n",
        "                                    for cell in header_row if cell)\n",
        "                is_session = any(re.search(session_plan_col_patterns[\"Session\"], cell, re.IGNORECASE)\n",
        "                                 for cell in header_row if cell) or (session_rows_extracted > 0)\n",
        "\n",
        "                # --- Process Metadata/Instructor Table ---\n",
        "                if is_metadata:\n",
        "                    # Process metadata and (if present) instructor details.\n",
        "                    for row in table:\n",
        "                        if len(row) < 2:\n",
        "                            continue\n",
        "                        row = [get_default(cell) for cell in row]\n",
        "                        key = row[0]\n",
        "                        value = row[1]\n",
        "                        for canonical, pattern in course_metadata_keys.items():\n",
        "                            if re.search(pattern, key, re.IGNORECASE):\n",
        "                                extracted_data[\"course_metadata\"][canonical] = value\n",
        "                                break\n",
        "                        for canonical, pattern in instructor_keys.items():\n",
        "                            if re.search(pattern, key, re.IGNORECASE):\n",
        "                                extracted_data[\"instructor_details\"][canonical] = value\n",
        "                                break\n",
        "                    session_count_expected = extracted_data[\"course_metadata\"].get(\"Total no. of sessions\", None)\n",
        "                    current_table_type = None  # Reset when metadata table appears.\n",
        "\n",
        "                # --- Process Standalone Instructor Table ---\n",
        "                elif is_instructor:\n",
        "                    for row in table:\n",
        "                        row = [get_default(cell) for cell in row]\n",
        "                        if len(row) < 2:\n",
        "                            continue\n",
        "                        key = row[0]\n",
        "                        value = row[1]\n",
        "                        for canonical, pattern in instructor_keys.items():\n",
        "                            if re.search(pattern, key, re.IGNORECASE):\n",
        "                                extracted_data[\"instructor_details\"][canonical] = value\n",
        "                                break\n",
        "                    current_table_type = None\n",
        "\n",
        "                # --- Process Assessment Table ---\n",
        "                elif is_assessment and (current_table_type != \"Session\"):\n",
        "                    current_table_type = \"assessment\"\n",
        "                    # Determine if a header row exists by checking for expected assessment columns.\n",
        "                    header_matches = sum(1\n",
        "                                         for canonical, pattern in assessment_col_patterns.items()\n",
        "                                         for cell in header_row\n",
        "                                         if cell and re.search(pattern, cell, re.IGNORECASE))\n",
        "                    # If at least two expected columns are present, assume the first row is a header.\n",
        "                    start_idx = 1 if header_matches >= 2 else 0\n",
        "\n",
        "                    prev_row_values = {}\n",
        "                    for row in table[start_idx:]:\n",
        "                        # Normalize cells using get_default.\n",
        "                        row = [get_default(cell) for cell in row]\n",
        "\n",
        "                        # For any cell that is \"NA\", fill it with the value from the previous row (if available).\n",
        "                        for idx in range(len(row)):\n",
        "                            if row[idx] == \"NA\" and idx in prev_row_values:\n",
        "                                row[idx] = prev_row_values[idx]\n",
        "\n",
        "                        # Update previous row values with the current row's non-\"NA\" cells.\n",
        "                        prev_row_values = {i: row[i] for i in range(len(row)) if row[i] != \"NA\"}\n",
        "\n",
        "                        # Ensure the row has at least three columns.\n",
        "                        if len(row) < 3:\n",
        "                            row += [\"NA\"] * (3 - len(row))\n",
        "\n",
        "                        extracted_data[\"assessment\"].append({\n",
        "                            \"Assessment Tool\": row[0],\n",
        "                            \"Percentage\": row[1],\n",
        "                            \"Description\": row[2]\n",
        "                        })\n",
        "\n",
        "\n",
        "                # --- Process Session Plan Table ---\n",
        "                elif is_session or (current_table_type == \"Session\"):\n",
        "                    if ((re.search(rf'\\b{session_count_expected}\\b', Session))):\n",
        "                        break\n",
        "                    current_table_type = \"Session\"  # Once Session headers are seen, remain in Session mode.\n",
        "                    # Decide if the first row is a header by matching expected Session plan columns.\n",
        "                    header_matches = sum(1\n",
        "                                         for canonical, pattern in session_plan_col_patterns.items()\n",
        "                                         for cell in header_row\n",
        "                                         if cell and re.search(pattern, cell, re.IGNORECASE))\n",
        "                    start_idx = 1 if header_matches >= 2 else 0\n",
        "\n",
        "                    for row in table[start_idx:]:\n",
        "                        row = [get_default(cell) for cell in row]\n",
        "                        # For merged cells, if any cell is \"NA\", do not auto-fill except for Session column.\n",
        "                        # (i.e. we do not propagate \"NA\" values for other columns.)\n",
        "                        if len(row) < 4:\n",
        "                            row += [\"NA\"] * (4 - len(row))\n",
        "                        # If the Session cell is blank, treat this row as a continuation of the previous Session.\n",
        "                        if (row[0] == \"NA\" or row[0].strip() == \"\") and extracted_data[\"session_plan\"]:\n",
        "                            last_entry = extracted_data[\"session_plan\"][-1]\n",
        "                            for col, key in zip([1, 2, 3], [\"Module\", \"Topic\", \"Chapter No / Reading material / Cases\"]):\n",
        "                                if row[col] != \"NA\":\n",
        "                                    if last_entry[key] != \"NA\":\n",
        "                                        last_entry[key] += \" \" + row[col]\n",
        "                                    else:\n",
        "                                        last_entry[key] = row[col]\n",
        "                            continue\n",
        "                        else:\n",
        "                            new_entry = {\n",
        "                                \"Session\": row[0],\n",
        "                                \"Module\": row[1],\n",
        "                                \"Topic\": row[2],\n",
        "                                \"Chapter No / Reading material / Cases\": row[3]\n",
        "                            }\n",
        "                            extracted_data[\"session_plan\"].append(new_entry)\n",
        "                            Session = new_entry[\"Session\"]\n",
        "                            session_rows_extracted += 1\n",
        "                else:\n",
        "                    # redundant code used for edge cases\n",
        "                    # If no header is detected, but we already have a current_table_type,\n",
        "                    # treat this table as a continuation of that type.\n",
        "                    if current_table_type == \"assessment\":\n",
        "                        header_matches = sum(1\n",
        "                                             for canonical, pattern in assessment_col_patterns.items()\n",
        "                                             for cell in header_row\n",
        "                                             if cell and re.search(pattern, cell, re.IGNORECASE))\n",
        "                        start_idx = 1 if header_matches >= 2 else 0\n",
        "                        prev_row_values = {}\n",
        "                        for row in table[start_idx:]:\n",
        "                            row = [get_default(cell) for cell in row]\n",
        "                            for idx in range(len(row)):\n",
        "                                if row[idx] == \"NA\" and idx in prev_row_values:\n",
        "                                    row[idx] = prev_row_values[idx]\n",
        "                            prev_row_values = {i: row[i] for i in range(len(row)) if row[i] != \"NA\"}\n",
        "                            if len(row) < 3:\n",
        "                                row += [\"NA\"] * (3 - len(row))\n",
        "                            extracted_data[\"assessment\"].append({\n",
        "                                \"Assessment Tool\": row[0],\n",
        "                                \"Percentage\": row[1],\n",
        "                                \"Description\": row[2]\n",
        "                            })\n",
        "\n",
        "                    elif current_table_type == \"Session\":\n",
        "                        if ((re.search(rf'\\b{session_count_expected}\\b', Session))):\n",
        "                          break\n",
        "                        header_matches = sum(1\n",
        "                                             for canonical, pattern in session_plan_col_patterns.items()\n",
        "                                             for cell in header_row\n",
        "                                             if cell and re.search(pattern, cell, re.IGNORECASE))\n",
        "                        start_idx = 1 if header_matches >= 2 else 0\n",
        "                        for row in table[start_idx:]:\n",
        "                            row = [get_default(cell) for cell in row]\n",
        "                            if len(row) < 4:\n",
        "                                row += [\"NA\"] * (4 - len(row))\n",
        "                            if (row[0] == \"NA\" or row[0].strip() == \"\") and extracted_data[\"session_plan\"]:\n",
        "                                last_entry = extracted_data[\"session_plan\"][-1]\n",
        "                                for col, key in zip([1, 2, 3], [\"Module\", \"Topic\", \"Chapter No / Reading material / Cases\"]):\n",
        "                                    if row[col] != \"NA\":\n",
        "                                        if last_entry[key] != \"NA\":\n",
        "                                            last_entry[key] += \" \" + row[col]\n",
        "                                        else:\n",
        "                                            last_entry[key] = row[col]\n",
        "                                continue\n",
        "                            else:\n",
        "                                new_entry = {\n",
        "                                    \"Session\": row[0],\n",
        "                                    \"Module\": row[1],\n",
        "                                    \"Topic\": row[2],\n",
        "                                    \"Chapter No / Reading material / Cases\": row[3]\n",
        "                                }\n",
        "                                extracted_data[\"session_plan\"].append(new_entry)\n",
        "                                Session = new_entry[\"Session\"]\n",
        "                                session_rows_extracted += 1\n",
        "\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "XI2LWKzfuSTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save to Output Folder**"
      ],
      "metadata": {
        "id": "Xxc-heRZuVFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_output(data, original_path, root_dir): #no subfolders\n",
        "    # Define the Google Drive output folder path\n",
        "    google_drive_folder = \"/content/drive/MyDrive/Outputs\"\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    Path(google_drive_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Extract file name without extension\n",
        "    file_name = os.path.basename(original_path)\n",
        "    json_filename = f\"{file_name}.json\"\n",
        "\n",
        "    # Full path for saving the JSON file in Google Drive\n",
        "    output_path = os.path.join(google_drive_folder, json_filename)\n",
        "\n",
        "    # Save JSON file\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "\n",
        "    print(f\"Saved output to: {output_path}\")"
      ],
      "metadata": {
        "id": "LzcdhGgtuXn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main**"
      ],
      "metadata": {
        "id": "AA5L5FNpuZ6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_courses(root_dir):\n",
        "    course_files = find_course_outlines(root_dir)\n",
        "\n",
        "    for file_info in course_files:\n",
        "        try:\n",
        "            if file_info[\"filename\"].lower().endswith(\".docx\"):\n",
        "                basic_info = extract_text_sections_from_docx(file_info[\"path\"])\n",
        "                data = extract_tables_from_docx(file_info[\"path\"])\n",
        "\n",
        "            elif file_info[\"filename\"].lower().endswith(\".pdf\"):\n",
        "                basic_info = extract_text_sections_from_pdf(file_info[\"path\"])\n",
        "                data = extract_tables_from_pdf(file_info[\"path\"])\n",
        "\n",
        "            # Add basic text sections (Introduction, Learning Outcomes, Pedagogy)\n",
        "            data[\"basic_info\"] = basic_info\n",
        "            # Add program/term info\n",
        "            data[\"program\"] = file_info[\"program\"]\n",
        "            data[\"term\"] = file_info[\"term\"]\n",
        "\n",
        "            save_output(data, file_info[\"path\"], root_dir)\n",
        "            print(f\"Processed: {file_info['path']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_info['path']}: {str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_all_courses(\"/content/drive/MyDrive/root\")"
      ],
      "metadata": {
        "id": "eg0dl6DXubou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2bcd9c2-e896-48f3-e022-086e7b8f834f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved output to: /content/drive/MyDrive/Outputs/CourseOutline_BusinessCommunication.pdf.json\n",
            "Processed: /content/drive/MyDrive/root/MBA09/term_2/CourseOutline_BusinessCommunication.pdf\n",
            "Saved output to: /content/drive/MyDrive/Outputs/CourseOutline_NLP.pdf.json\n",
            "Processed: /content/drive/MyDrive/root/MSDSM/term_4/CourseOutline_NLP.pdf\n",
            "Saved output to: /content/drive/MyDrive/Outputs/CourseOutline_StoryTellingwithData.docx.json\n",
            "Processed: /content/drive/MyDrive/root/MSDSM/term_4/CourseOutline_StoryTellingwithData.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OWL Generation**"
      ],
      "metadata": {
        "id": "Z5y0kqMczWT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def sanitize_iri(raw_input: str) -> str:\n",
        "    \"\"\"Sanitize strings for use in IRIs. Replaces spaces/special chars with underscores.\"\"\"\n",
        "    sanitized = re.sub(r'[^\\w]', '_', raw_input.strip().lower())  # Replace non-alphanumerics with _\n",
        "    sanitized = re.sub(r'_+', '_', sanitized)  # Collapse multiple underscores\n",
        "    return sanitized.strip('_')  # Remove leading/trailing underscores\n",
        "\n",
        "def create_ontology(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Reset the ontology world to start fresh\n",
        "    world = World()\n",
        "    owlready2.default_world = world\n",
        "\n",
        "    # Create a fresh ontology (do not load from file)\n",
        "    onto = get_ontology(\"http://www.example.org/university.owl#\")\n",
        "\n",
        "    with onto:\n",
        "        # Define Core Hierarchy Classes\n",
        "        class Program(owlready2.Thing): pass\n",
        "        class Term(owlready2.Thing): pass\n",
        "        class Course(owlready2.Thing): pass\n",
        "\n",
        "        # Define Course Component Classes\n",
        "        class BasicInfo(owlready2.Thing): pass\n",
        "        class CourseMetadata(owlready2.Thing): pass\n",
        "        class InstructorDetails(owlready2.Thing): pass\n",
        "        class Assessment(owlready2.Thing): pass\n",
        "        class SessionPlan(owlready2.Thing): pass\n",
        "\n",
        "        # Data Properties for Program and Term\n",
        "        class programName(DataProperty, FunctionalProperty):\n",
        "            domain = [Program]\n",
        "            range = [str]\n",
        "\n",
        "        class termNumber(DataProperty, FunctionalProperty):\n",
        "            domain = [Term]\n",
        "            range = [str]\n",
        "\n",
        "        # BasicInfo Properties\n",
        "        class Introduction(DataProperty, FunctionalProperty):\n",
        "            domain = [BasicInfo]\n",
        "            range = [str]\n",
        "\n",
        "        class LearningOutcomes(DataProperty, FunctionalProperty):\n",
        "            domain = [BasicInfo]\n",
        "            range = [str]\n",
        "\n",
        "        class PedagogyUsed(DataProperty, FunctionalProperty):\n",
        "            domain = [BasicInfo]\n",
        "            range = [str]\n",
        "\n",
        "        # CourseMetadata Properties\n",
        "        class CourseCodeTitle(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class CourseType(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class Prerequisites(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class CourseCredit(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class TotalSessions(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class SessionDuration(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class YearBatch(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        class Sections(DataProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [str]\n",
        "\n",
        "        # InstructorDetails Properties\n",
        "        class Instructors(DataProperty, FunctionalProperty):\n",
        "            domain = [InstructorDetails]\n",
        "            range = [str]\n",
        "\n",
        "        class ContactDetails(DataProperty, FunctionalProperty):\n",
        "            domain = [InstructorDetails]\n",
        "            range = [str]\n",
        "\n",
        "        class Office(DataProperty, FunctionalProperty):\n",
        "            domain = [InstructorDetails]\n",
        "            range = [str]\n",
        "\n",
        "        class ConsultationHours(DataProperty, FunctionalProperty):\n",
        "            domain = [InstructorDetails]\n",
        "            range = [str]\n",
        "\n",
        "        # Assessment Properties\n",
        "        class AssessmentTool(DataProperty, FunctionalProperty):\n",
        "            domain = [Assessment]\n",
        "            range = [str]\n",
        "\n",
        "        class Percentage(DataProperty, FunctionalProperty):\n",
        "            domain = [Assessment]\n",
        "            range = [str]\n",
        "\n",
        "        class AssessmentDescription(DataProperty, FunctionalProperty):\n",
        "            domain = [Assessment]\n",
        "            range = [str]\n",
        "\n",
        "        # SessionPlan Properties\n",
        "        class Session(DataProperty, FunctionalProperty):  # Renamed from SessionNumber for clarity\n",
        "            domain = [SessionPlan]\n",
        "            range = [str]\n",
        "\n",
        "        class Module(DataProperty, FunctionalProperty):\n",
        "            domain = [SessionPlan]\n",
        "            range = [str]\n",
        "\n",
        "        class Topic(DataProperty, FunctionalProperty):\n",
        "            domain = [SessionPlan]\n",
        "            range = [str]\n",
        "\n",
        "        class ReadingMaterial(DataProperty, FunctionalProperty):\n",
        "            domain = [SessionPlan]\n",
        "            range = [str]\n",
        "\n",
        "        # Object Properties with Bidirectional Links\n",
        "        class hasTerm(ObjectProperty):\n",
        "            domain = [Program]\n",
        "            range = [Term]\n",
        "        class belongsToProgram(ObjectProperty):\n",
        "            domain = [Term]\n",
        "            range = [Program]\n",
        "            inverse_property = hasTerm\n",
        "\n",
        "        class hasCourse(ObjectProperty):\n",
        "            domain = [Term]\n",
        "            range = [Course]\n",
        "        class belongsToTerm(ObjectProperty):\n",
        "            domain = [Course]\n",
        "            range = [Term]\n",
        "            inverse_property = hasCourse\n",
        "\n",
        "        class hasBasicInfo(ObjectProperty, FunctionalProperty):\n",
        "            domain = [Course]\n",
        "            range = [BasicInfo]\n",
        "        class infoOfCourse(ObjectProperty, FunctionalProperty):\n",
        "            domain = [BasicInfo]\n",
        "            range = [Course]\n",
        "            inverse_property = hasBasicInfo\n",
        "\n",
        "        class hasCourseMetadata(ObjectProperty, FunctionalProperty):\n",
        "            domain = [Course]\n",
        "            range = [CourseMetadata]\n",
        "        class partOfCourse(ObjectProperty, FunctionalProperty):\n",
        "            domain = [CourseMetadata]\n",
        "            range = [Course]\n",
        "            inverse_property = hasCourseMetadata\n",
        "\n",
        "        class hasInstructorDetails(ObjectProperty, FunctionalProperty):\n",
        "            domain = [Course]\n",
        "            range = [InstructorDetails]\n",
        "        class teachesCourse(ObjectProperty, FunctionalProperty):\n",
        "            domain = [InstructorDetails]\n",
        "            range = [Course]\n",
        "            inverse_property = hasInstructorDetails\n",
        "\n",
        "        class hasAssessment(ObjectProperty):\n",
        "            domain = [Course]\n",
        "            range = [Assessment]\n",
        "        class assessmentOf(ObjectProperty):\n",
        "            domain = [Assessment]\n",
        "            range = [Course]\n",
        "            inverse_property = hasAssessment\n",
        "\n",
        "        class hasSessionPlan(ObjectProperty):\n",
        "            domain = [Course]\n",
        "            range = [SessionPlan]\n",
        "        class sessionOf(ObjectProperty):\n",
        "            domain = [SessionPlan]\n",
        "            range = [Course]\n",
        "            inverse_property = hasSessionPlan\n",
        "\n",
        "        # ---- Clear any existing individuals (in case ontology already had some) ----\n",
        "        for cls in onto.classes():\n",
        "            for inst in list(cls.instances()):\n",
        "                owlready2.destroy_entity(inst)\n",
        "\n",
        "    # Process JSON files from input_folder\n",
        "    processed_files = 0\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if not filename.endswith(\".json\"):\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error reading {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Extract program and term (lowercase for consistency)\n",
        "        program_name = sanitize_iri(data.get(\"program\", \"\"))  # Uses helper\n",
        "        term_name = sanitize_iri(data.get(\"term\", \"\"))\n",
        "\n",
        "        if not (program_name and term_name):\n",
        "            logger.warning(f\"Skipping {filename}: Missing program/term\")\n",
        "            continue\n",
        "\n",
        "        # --- Program: Check for existing instance ---\n",
        "        existing_program = onto.search_one(iri=f\"*#{program_name}\")\n",
        "        if existing_program:\n",
        "            program = existing_program\n",
        "        else:\n",
        "            program = onto.Program(program_name)\n",
        "            program.programName = program_name\n",
        "\n",
        "        # --- Term: Use composite ID to ensure uniqueness ---\n",
        "        term_id = f\"{program_name}_{term_name}\"\n",
        "        term = onto.Term(term_id)\n",
        "\n",
        "        # Extract term number directly from the \"term\" field\n",
        "        if \"_\" in term_name:\n",
        "            term.termNumber = term_name.split('_')[-1]  # \"term_1\" â \"1\"\n",
        "        else:\n",
        "            term.termNumber = term_name  # Fallback for invalid formats\n",
        "            logger.warning(f\"Unstructured term name in {filename}: {term_name}\")\n",
        "        program.hasTerm.append(term)\n",
        "        term.belongsToProgram.append(program)\n",
        "\n",
        "        # --- Course: Check for existing Course by course code ---\n",
        "        try:\n",
        "            course_title = data[\"course_metadata\"][\"Course Code and Course Title\"]\n",
        "            #course_code = sanitize_iri(course_title.split()[0])  # Sanitize code\n",
        "            course_code = sanitize_iri(course_title)\n",
        "        except KeyError:\n",
        "            logger.error(f\"Missing course metadata in {filename}\")\n",
        "            continue\n",
        "\n",
        "        existing_course = onto.search_one(iri=f\"*#{course_code}\")\n",
        "        if existing_course:\n",
        "            course = existing_course\n",
        "        else:\n",
        "            course = onto.Course(course_code)\n",
        "            course.name = course_code\n",
        "\n",
        "        # Link course to term if not already linked\n",
        "        if course not in term.hasCourse:\n",
        "            term.hasCourse.append(course)\n",
        "        if term not in course.belongsToTerm:\n",
        "            course.belongsToTerm.append(term)\n",
        "\n",
        "        # --- Basic Info ---\n",
        "        if 'basic_info' in data:\n",
        "            if course.hasBasicInfo:\n",
        "                bi = course.hasBasicInfo\n",
        "            else:\n",
        "                bi = onto.BasicInfo()\n",
        "                course.hasBasicInfo = bi\n",
        "            bi.Introduction = data['basic_info'].get('Introduction', '')\n",
        "            bi.LearningOutcomes = data['basic_info'].get('Learning Outcomes', '')\n",
        "            bi.PedagogyUsed = data['basic_info'].get('Pedagogy', '')\n",
        "            bi.infoOfCourse = course\n",
        "\n",
        "        # --- Course Metadata ---\n",
        "        if 'course_metadata' in data:\n",
        "            if course.hasCourseMetadata:\n",
        "                cm = course.hasCourseMetadata\n",
        "            else:\n",
        "                cm = onto.CourseMetadata()\n",
        "                course.hasCourseMetadata = cm\n",
        "            cm_data = data['course_metadata']\n",
        "            cm.CourseCodeTitle = cm_data.get('Course Code and Course Title', '')\n",
        "            cm.CourseType = cm_data.get('Course type', '')\n",
        "            cm.Prerequisites = cm_data.get('Pre-requisites (if any)', 'None')\n",
        "            cm.CourseCredit = cm_data.get('Course Credit', '')\n",
        "            try:\n",
        "                cm.TotalSessions = cm_data.get('Total no. of sessions', 0)\n",
        "            except ValueError:\n",
        "                logger.warning(f\"Invalid TotalSessions in {filename}\")\n",
        "                cm.TotalSessions = 0\n",
        "            cm.SessionDuration = cm_data.get('Session Duration', '')\n",
        "            cm.YearBatch = cm_data.get('Year and Batch', '')\n",
        "            cm.Sections = cm_data.get('Sections (if any)', '')\n",
        "            cm.partOfCourse = course\n",
        "\n",
        "        # --- Instructor Details ---\n",
        "        if 'instructor_details' in data:\n",
        "            if course.hasInstructorDetails:\n",
        "                instr = course.hasInstructorDetails\n",
        "            else:\n",
        "                instr = onto.InstructorDetails()\n",
        "                course.hasInstructorDetails = instr\n",
        "            instr_data = data['instructor_details']\n",
        "            instr.Instructors = instr_data.get('Instructor(s)', '')\n",
        "            instr.ContactDetails = instr_data.get('Contact Details', '')\n",
        "            instr.Office = instr_data.get('Office', 'NA')\n",
        "            instr.ConsultationHours = instr_data.get('Consultation Hours', 'NA')\n",
        "            instr.teachesCourse = course\n",
        "\n",
        "        # --- Assessments ---\n",
        "        for assessment_data in data.get('assessment', []):\n",
        "            # Check for duplicate assessment for this course\n",
        "            duplicate_assessment = False\n",
        "            for a in course.hasAssessment:\n",
        "                if (a.AssessmentTool == assessment_data.get('Assessment Tool', '') and\n",
        "                    a.Percentage == assessment_data.get('Percentage', '0.0') and\n",
        "                    a.AssessmentDescription == assessment_data.get('Description', '')):\n",
        "                    duplicate_assessment = True\n",
        "                    break\n",
        "            if duplicate_assessment:\n",
        "                continue\n",
        "\n",
        "            assessment = onto.Assessment()\n",
        "            assessment.AssessmentTool = assessment_data.get('Assessment Tool', '')\n",
        "            assessment.Percentage = assessment_data.get('Percentage', '0.0')\n",
        "            assessment.AssessmentDescription = assessment_data.get('Description', '')\n",
        "            course.hasAssessment.append(assessment)\n",
        "            assessment.assessmentOf.append(course)\n",
        "\n",
        "        # --- Session Plans ---\n",
        "        for session_data in data.get('session_plan', []):\n",
        "            # Check for duplicate session plan\n",
        "            duplicate_session = False\n",
        "            for sp in course.hasSessionPlan:\n",
        "                if (sp.Session == session_data.get('Session', '') and\n",
        "                    sp.Module == session_data.get('Module', '') and\n",
        "                    sp.Topic == session_data.get('Topic', '') and\n",
        "                    sp.ReadingMaterial == session_data.get('Chapter No / Reading material / Cases', '')):\n",
        "                    duplicate_session = True\n",
        "                    break\n",
        "            if duplicate_session:\n",
        "                continue\n",
        "\n",
        "            sp = onto.SessionPlan()\n",
        "            sp.Session = session_data.get('Session', '')\n",
        "            sp.Module = session_data.get('Module', '')\n",
        "            sp.Topic = session_data.get('Topic', '')\n",
        "            sp.ReadingMaterial = session_data.get('Chapter No / Reading material / Cases', '')\n",
        "            course.hasSessionPlan.append(sp)\n",
        "            sp.sessionOf.append(course)\n",
        "\n",
        "        processed_files += 1\n",
        "\n",
        "    output_path = os.path.join(output_folder, \"university_courses.owl\")\n",
        "    if os.path.exists(output_path):\n",
        "        os.remove(output_path)\n",
        "\n",
        "    onto.save(file=output_path, format=\"rdfxml\")\n",
        "    logger.info(f\"Processed {processed_files} files. Ontology saved to {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_dir = \"/content/drive/MyDrive/Outputs\"\n",
        "    output_dir = \"/content/drive/MyDrive/Ontology\"\n",
        "    create_ontology(input_dir, output_dir)"
      ],
      "metadata": {
        "id": "wsgrGPNLzkvP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}